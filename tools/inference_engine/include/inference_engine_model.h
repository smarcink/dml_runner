#ifndef INFERENCE_ENGINE_MODEL_DESCRIPTOR_H
#define INFERENCE_ENGINE_MODEL_DESCRIPTOR_H

#include "inference_engine.h"
#include "inference_engine_operators.h"
#include "inference_engine_export.h"
#include "inference_engine_tensor.h"
#include <stdbool.h>

#ifdef __cplusplus
extern "C" {
#endif


typedef struct _inference_engine_model_descriptor_t* inference_engine_model_descriptor_t;
typedef struct _inference_engine_model_t* inference_engine_model_t;

typedef struct _inference_engine_tensor_mapping_t
{
    inference_engine_node_id_t id;
    inference_engine_tensor_t tensor;
} inference_engine_tensor_mapping_t;

INFERENCE_ENGINE_API inference_engine_model_descriptor_t inferenceEngineCreateModelDescriptor();
INFERENCE_ENGINE_API inference_engine_node_id_t inferenceEngineModelDescriptorAddPort(inference_engine_model_descriptor_t model_desc, inference_engine_port_desc_t desc);
INFERENCE_ENGINE_API inference_engine_node_id_t inferenceEngineModelDescriptorAddMatMul(inference_engine_model_descriptor_t model_desc, inference_engine_matmul_desc_t desc);
INFERENCE_ENGINE_API inference_engine_node_id_t inferenceEngineModelDescriptorAddActivation(inference_engine_model_descriptor_t model_desc, inference_engine_activation_desc_t desc);
INFERENCE_ENGINE_API inference_engine_node_id_t inferenceEngineModelDescriptorAddElementwise(inference_engine_model_descriptor_t model_desc, inference_engine_elementwise_desc_t desc);
INFERENCE_ENGINE_API inference_engine_node_id_t inferenceEngineModelDescriptorAddConvolution(inference_engine_model_descriptor_t model_desc, inference_engine_convolution_desc_t desc);

INFERENCE_ENGINE_API bool inferenceEngineSetNodeName(inference_engine_model_descriptor_t model_desc, inference_engine_node_id_t node_id, const char* name);

//INFERENCE_ENGINE_API inference_engine_model_descriptor_t inferenceEngineCreateModelDescriptor(inference_engine_node_t* out_nodes, uint32_t out_nodes_count);
INFERENCE_ENGINE_API void inferenceEngineDestroyModelDescriptor(inference_engine_model_descriptor_t md);
INFERENCE_ENGINE_API void inferenceEngineDestroyModel(inference_engine_model_t model);
INFERENCE_ENGINE_API inference_engine_model_t inferenceEngineCompileModelDescriptor(inference_engine_context_handle_t context, inference_engine_stream_t stream, inference_engine_model_descriptor_t model_desc, inference_engine_tensor_mapping_t* input_mapping_list, size_t input_mapping_size);
//set resource for inputs and outputs
INFERENCE_ENGINE_API bool inferenceEngineModelSetResource(inference_engine_model_t model, inference_engine_node_id_t id, inference_engine_resource_t resource);
// call with empty list to get size
INFERENCE_ENGINE_API bool inferenceEngineModelGetOutputs(inference_engine_model_t model, inference_engine_tensor_mapping_t* list, size_t* size);
INFERENCE_ENGINE_API bool inferenceEngineExecuteModel(inference_engine_model_t model, inference_engine_stream_t stream);

#ifdef __cplusplus
}
#endif

#endif  // INFERENCE_ENGINE_MODEL_DESCRIPTOR_H